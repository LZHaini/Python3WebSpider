# 第四章 解析库的使用

上一章中，我们实现了一个最基本的爬虫，但提取页面信息时使用的是正则表达式，这还是比较烦琐，而且万一有地方写错了，可能导致匹配失败，所以使用正则表达式提取页面信息多多少少还是有些不方便。

对于网页的节点来说，它可以定义 id、class 或其他属性。而且节点之间还有层次关系，在网页中可以通过 XPath 或 CSS 选择器来定位一个或多个节点。那么，在页面解析时，利用 XPath 或 CSS 选择器来提取某个节点，然后再调用相应方法获取它的正文内容或者属性，不就可以提取我们想要的任意信息了吗？

在 Python 中，怎样实现这个操作呢？不用担心，这种解析库已经非常多，其中比较强大的库有 lxml、Beautiful Soup、pyquery 等，本章就来介绍这 3 个解析库的用法。有了它们，我们就不用再为正则表达式发愁，而且解析效率也会大大提高。